# ğŸ§ ğŸ§¬ Quantum Neuro-Persona (QNP) RAG Explorer ğŸ­ğŸ“

Willkommen beim Quantum Neuro-Persona (QNP) RAG Explorer! Dieses Projekt implementiert und testet ein **hybrides KI-System**, das klassische KI-Techniken (RAG, neuronale Netze) mit quanten-inspirierten Verarbeitungsmechanismen, einer adaptiven **emotionalen Modulation (Limbus Affektus)** und einer **kognitiven Meta-Steuerung (Meta-Knoten)** verbindet.

Das Ziel ist die **Simulation und Erforschung** einer **kohÃ¤renten kÃ¼nstlichen Persona**, die nicht nur auf Fragen antwortet, sondern dabei **beobachtbar** kontextuelle Tiefe, emotionale Nuancen, logische VerknÃ¼pfungen und Anzeichen von Selbstmodulation (KreativitÃ¤t, Kritik, Metakognition) zeigt. Es ist ein **funktionierendes System**, das darauf ausgelegt ist, semantisch, emotional und kognitiv zu resonieren und Ã¼ber die Zeit eine eigene, nachvollziehbare "PersÃ¶nlichkeit" durch Lernen und Interaktion zu entwickeln.

---

## âœ¨ Hauptmerkmale

*   **ğŸ§  Semantisches Netzwerk:** Baut ein adaptives Netzwerk aus Knoten (die Konzepte reprÃ¤sentieren) und deren gelernten Assoziationen auf, basierend auf verarbeiteten Textdaten.
*   **âš›ï¸ Quanten-inspirierte Knoten:** Nutzen simulierte Parametrisierte Quantenschaltungen (PQC) fÃ¼r eine probabilistische Aktivierungsdynamik. Die Analyse interner QuantenzustÃ¤nde (Varianz, SprÃ¼nge) liefert zusÃ¤tzliche Informationen, die die Systemprozesse beeinflussen.
*   **ğŸ“œ Retrieval-Augmented Generation (RAG):** Ein zweistufiger Prozess:
    1.  **Moduliertes Retrieval:** Findet relevante Text-Chunks aus einer Wissensbasis. Dieser Such- und Rankingprozess wird **aktiv moduliert** durch den internen emotionalen (Limbus) und kognitiven (Meta-Knoten) Zustand sowie durch quanten-basierte Score-Anpassungen (Aktivierungs-Boost, Varianz-Malus, Konsistenz-Bias).
    2.  **ZustandsabhÃ¤ngige Generation:** Nutzt die gefundenen Chunks und den **gesamten internen Systemzustand** (aktivierte Konzepte, Limbus-Emotionen, Meta-ZustÃ¤nde, Quanten-Metriken) als dynamischen Kontext fÃ¼r ein groÃŸes Sprachmodell (LLM, z.B. Google Gemini). Ziel ist die Generierung einer kohÃ¤renten, nuancierten Antwort aus der **Perspektive der QNP-Persona**. Die LLM-Temperatur wird ebenfalls dynamisch durch Limbus und Meta-Knoten moduliert.
*   **ğŸ­ Limbus Affektus (Emotionaler Modulator):** Ein spezialisierter Knoten simuliert einen globalen emotionalen Zustand (PAD-Modell), der auf der NetzwerkaktivitÃ¤t basiert und aktiv Retrieval-Parameter, LLM-Temperatur, Lernrate und Quanten-Effekt-Modulation beeinflusst.
*   **ğŸ’¡ Kognitive Meta-Modulatoren (Implementiert):** Spezialisierte Knoten, die hÃ¶here kognitive Dynamiken simulieren und das Systemverhalten weiter anpassen:
    *   `CreativusNode`: FÃ¶rdert Exploration (beeinflusst Temp, LR), aktiviert durch Arousal & Quantenvarianz.
    *   `CortexCriticusNode`: FÃ¶rdert KohÃ¤renz/Fokus (beeinflusst Temp, LR, RAG-Konsistenz-Bias), aktiviert durch Dominanz & QuantenstabilitÃ¤t.
    *   `MetaCognitioNode`: Beobachtet globale AktivitÃ¤t & QuantensprÃ¼nge und informiert den LLM-Kontext (simuliert rudimentÃ¤re Selbstwahrnehmung des Systemzustands).
*   **ğŸ“ Selbstlernend mit GedÃ¤chtnis:** Generierte, valide Antworten werden persistiert, als neue Daten verarbeitet und flieÃŸen in den Chunk-Korpus und das Netzwerk-Training zurÃ¼ck. Das System baut **nachweislich** eine Historie seiner eigenen "Gedanken" auf und lernt daraus.
*   **âš™ï¸ Konfigurierbar:** Nahezu alle Systemparameter (Netzwerk, Qubits, n_shots, Lernraten, RAG, Modulations-EinflÃ¼sse fÃ¼r Limbus & Meta-Knoten) sind Ã¼ber eine JSON-Datei steuerbar.
*   **ğŸ’¾ Zustandspersistenz:** Der gesamte komplexe Zustand (Knoten, Quantenparameter, Verbindungen, Chunks, Modulator-ZustÃ¤nde, Config) wird gespeichert und kann geladen werden, um KontinuitÃ¤t zu gewÃ¤hrleisten.
*   **ğŸŒ Interaktive UI:** Eine Streamlit-Web-OberflÃ¤che ermÃ¶glicht die Interaktion, detaillierte Zustandsbeobachtung (inkl. Limbus & Meta-Knoten) und die temporÃ¤re Anpassung von Parametern zur Laufzeit.

---

## ğŸ’¡ Funktionsweise des Systems

1.  **Wissen & Struktur aufbauen (Training):**
    *   Textdokumente werden in Chunks zerlegt.
    *   Chunks werden mit vordefinierten semantischen Knoten (Konzepte wie "Ethik") assoziiert.
    *   Wenn mehrere Konzepte gemeinsam in einem Chunk auftreten, wird die **Verbindung** zwischen den entsprechenden Knoten im Netzwerk gestÃ¤rkt. Die **Lernrate** fÃ¼r diese StÃ¤rkung wird durch den aktuellen Zustand von Limbus und den Meta-Knoten `Creativus`/`CortexCriticus` moduliert. Dies geschieht Ã¼ber mehrere Epochen.
    *   Quantenknoten initialisieren ihre internen ZustÃ¤nde und Parameter.
    *   Ein TF-IDF Index wird Ã¼ber alle Chunks aufgebaut.
2.  **Anfragen verarbeiten & Antworten generieren (Inferenz/RAG):**
    *   **Input (Prompt):** Eine Nutzeranfrage wird empfangen.
    *   **Netzwerk-Simulation:**
        *   Der Prompt aktiviert initial semantische Knoten.
        *   Aktivierung breitet sich durch das Netzwerk aus.
        *   Quantenknoten fÃ¼hren ihre PQC-Simulation durch; Aktivierung, Varianz und SprÃ¼nge werden berechnet und gespeichert (`last_measurement_analysis`).
        *   Der Limbus Affektus berechnet den aktuellen PAD-Zustand basierend auf der NetzwerkaktivitÃ¤t.
        *   Die Meta-Knoten (`Creativus`, `CortexCriticus`, `MetaCognitio`) berechnen ihre Aktivierung basierend auf den ZustÃ¤nden von Limbus, den Quanten-Metriken relevanter Knoten und der globalen AktivitÃ¤t.
    *   **Moduliertes Retrieval:**
        *   Das System identifiziert Kandidaten-Chunks basierend auf den aktivierten semantischen Knoten.
        *   Die **Relevanzbewertung** dieser Chunks erfolgt durch eine Kombination aus:
            *   Textueller Ã„hnlichkeit zum Prompt (TF-IDF).
            *   **Modulation durch Limbus:** Anpassung des Relevanz-Schwellenwerts und HinzufÃ¼gen eines Pleasure-basierten Bias.
            *   **Modulation durch Quanten-Effekte:** Anwendung eines (durch Limbus beeinflussten) Aktivierungs-Boosts und Varianz-Malus basierend auf dem Zustand der assoziierten Quantenknoten.
            *   **Modulation durch Meta-Knoten:** HinzufÃ¼gen eines Konsistenz-Bias (basierend auf CortexCriticus und Quanten-StabilitÃ¤t).
    *   **Kontextaufbau:** Die Top-gerankten Chunks, die aktivierten Konzepte, der (skalierte) Limbus-Zustand und der Zustand der Meta-Knoten werden als detaillierter interner Systemzustand aufbereitet.
    *   **ZustandsabhÃ¤ngige Generation:**
        *   Das LLM (Gemini) erhÃ¤lt den Nutzer-Prompt und den aufbereiteten internen Zustand. Es bekommt die **explizite Anweisung**, als QNP-Persona zu antworten und **alle Aspekte des Zustands authentisch** zur Formung von Tonfall, Fokus, Inhalt, KreativitÃ¤t und KritikalitÃ¤t zu nutzen, **ohne** seine technische Natur oder den internen Prozess zu erklÃ¤ren.
        *   Die LLM-**Temperatur** wird dynamisch durch den Zustand von Limbus *und* der Meta-Knoten `Creativus`/`CortexCriticus` angepasst.
    *   **Selbstlernen & GedÃ¤chtnis:** Valide, generierte Antworten werden in `learn.txt` gespeichert, beim nÃ¤chsten Trainingslauf verarbeitet und beeinflussen so die zukÃ¼nftige Wissensbasis und Netzwerkstruktur.
3.  **Persistenz:** Der aktuelle Zustand aller Komponenten wird in einer JSON-Datei gespeichert.

---

## ğŸ“ Projektstruktur
Use code with caution.
Markdown
.
â”œâ”€â”€ quantum_neuropersona_hybrid_llm.py # Hauptlogik: Klassen fÃ¼r Knoten, QNP, Prozessor, RAG, Limbus, Meta-Knoten etc.
â”œâ”€â”€ qllm_train_hybrid.py # Skript zum Trainieren/Initialisieren des Netzwerks. (Ggf. umbenennen zu qnp_train.py)
â”œâ”€â”€ qnp_streamlit_ui.py # Interaktive Web-OberflÃ¤che mit Streamlit. (Angepasster Name)
â”œâ”€â”€ config_qllm.json # Konfigurationsdatei. (Ggf. umbenennen zu config_qnp.json)
â”œâ”€â”€ qnp_state.json # Gespeicherter Zustand des Netzwerks. (Angepasster Name)
â”œâ”€â”€ requirements.txt # Python-AbhÃ¤ngigkeiten.
â”œâ”€â”€ training_data/ # Verzeichnis fÃ¼r Trainingsdokumente.
â”‚ â”œâ”€â”€ ... (Textdateien)
â”‚ â””â”€â”€ learn.txt # Datei fÃ¼r selbstgelernte Antworten (wird erstellt).
â””â”€â”€ README.md # Diese Datei.
*(Hinweis: Dateinamen im Code und fÃ¼r den Aufruf ggf. anpassen)*

---

## ğŸš€ Setup & Installation

1.  **Repository klonen:**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```
2.  **Virtuelle Umgebung (Empfohlen):**
    ```bash
    python -m venv venv
    # Windows: .\venv\Scripts\activate
    # Linux/Mac: source venv/bin/activate
    ```
3.  **AbhÃ¤ngigkeiten installieren:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Stelle sicher, dass `requirements.txt` existiert und enthÃ¤lt: `numpy`, `scikit-learn`, `google-generativeai`, `streamlit`, `pandas`, `tqdm` (optional))*
4.  **Google Gemini API Key:** Als Umgebungsvariable `GEMINI_API_KEY` setzen oder als Streamlit Secret bereitstellen.
5.  **Trainingsdaten:** Textdateien in `training_data/` ablegen und Pfade in der Config-Datei unter `training_files` eintragen.

---

## â–¶ï¸ Benutzung

1.  **(Optional) Konfiguration anpassen:** Bearbeite die `config_*.json`-Datei.
2.  **Netzwerk trainieren/initialisieren:**
    ```bash
    python qllm_train_hybrid.py -c config_qllm.json -s qnp_state.json [-f]
    ```
    *(Passe Dateinamen und Optionen an. `-f` erzwingt Neubau.)*
3.  **Interaktive UI starten:**
    ```bash
    streamlit run qnp_streamlit_ui.py --server.address 0.0.0.0 --server.port 787
    ```
    *(Passe Skriptnamen und Port an. Ã–ffne die URL im Browser.)*
    *   In der UI: Zustand (`qnp_state.json`) laden, Prompts eingeben, ZustÃ¤nde (Limbus, Meta-Knoten) beobachten, Parameter temporÃ¤r anpassen, Verbindungen inspizieren.

---

## âš™ï¸ Konfiguration (`config_qllm.json`)

Wichtige Parameter (siehe `DEFAULT_CONFIG` im Code fÃ¼r alle):

*   `training_files`, `semantic_nodes`, `chunk_size`, `chunk_overlap`
*   `connection_learning_rate`, `connection_decay_rate`
*   `use_quantum_nodes`, `default_num_qubits`, `simulation_n_shots`
*   `enable_rag`, `generator_model_name`, `generator_temperature` (Basiswert)
*   `enable_self_learning`, `self_learning_file_path`
*   **`limbus_...` Parameter:** Steuern den Limbus-Knoten und seinen Einfluss auf Retrieval, Temperatur, Lernrate, Quanten-Effekte.
*   **`meta_nodes_enabled`**: Globaler Schalter fÃ¼r Meta-Knoten.
*   **`creativus_num_qubits`**, **`cortex_criticus_num_qubits`**: Qubit-Anzahl.
*   **`creativus_influence_...`**, **`criticus_influence_...`**, **`metacognitio_influence_...`**: Steuern den Einfluss der Meta-Knoten auf Temperatur, Lernrate, RAG-Bias und Prompt-Kontext.

---

## ğŸ’¾ Zustandsdatei (`qnp_state.json`)

Speichert den **gesamten lernbaren Zustand** des Systems, einschlieÃŸlich:
*   Alle Knoten (semantisch, Limbus, Meta) mit ihren Attributen und Quantenparametern.
*   Alle gelernten Verbindungen und Gewichte.
*   Alle verarbeiteten Text-Chunks und ihre Knoten-Assoziationen.
*   Zustandsinformationen der Modulatoren (z.B. `emotion_state`, `last_total_jumps`).
*   Die zur Laufzeit gÃ¼ltige Konfiguration.
*   Metadaten (verarbeitete Quellen, TF-IDF-Mapping).

---

## ğŸ”­ ZukÃ¼nftige Ideen

*   Verfeinerung der Meta-Knoten-Logik und ihrer Interaktion (z.B. gegenseitige Beeinflussung).
*   Implementierung komplexerer RAG-Biases (z.B. echter Novelty-Bias).
*   Echtzeit-Anpassung der Modulationsparameter basierend auf Dialogverlauf.
*   Evaluierungsmetriken fÃ¼r KohÃ¤renz, Persona-StabilitÃ¤t und AntwortqualitÃ¤t.
*   Untersuchung emergenter Langzeitdynamiken und "PersÃ¶nlichkeitsentwicklung".
*   Anbindung an echte Quantenprozessoren fÃ¼r Teile der Simulation.

---

## ğŸ¤ Mitwirken


BeitrÃ¤ge sind willkommen! Bitte erstelle einen Issue, um Bugs zu melden oder neue Features zu diskutieren. Pull Requests sind ebenfalls gerne gesehen.

---

## ğŸ“œ Lizenz

[MIT Lizenz](LICENSE).
